{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity CarND Project 2: Traffic Sign Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = \"train.p\"\n",
    "testing_file = \"test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value.\n",
    "import random\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = \"{}x{}\".format(len(X_train[0]), len(X_train[0][0]))\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = max(train['labels'])+1\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "num_displayed = range(43)\n",
    "row_classes = 6\n",
    "col_classes = 2\n",
    "num_rows = (len(num_displayed) + row_classes -1)//row_classes\n",
    "\n",
    "fg = plt.figure(figsize=(col_classes*row_classes,num_rows))\n",
    "gridspace1 = gridspec.GridSpec(num_rows,col_classes*row_classes)\n",
    "gridspace1.update(wspace=0.05, hspace=0.05) \n",
    "for i in range(len(num_displayed)):\n",
    "    index = np.where(y_train==num_displayed[i])[0]\n",
    "    random_selection = np.random.choice(index, col_classes, replace = False)\n",
    "    image_samples = X_train[random_selection,:,:,:]\n",
    "    for j in range(col_classes):\n",
    "        axis = plt.subplot(gridspace1[i*col_classes + j])\n",
    "        plt.imshow(image_samples[j,:,:,:])\n",
    "        axis.text(2,6,str(i), bbox={'facecolor':'red', 'alpha':0.4, 'pad':2})\n",
    "        plt.axis('off')\n",
    "fg.suptitle('Training Data Example Showcase', fontsize=12, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ctr = Counter(sorted(y_train))\n",
    "print('Amount of Each Traffic Sign')\n",
    "labels, values = zip(*(ctr.items()))\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1.0\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 2, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Design and Test a Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm_notebook\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_color(image_data):\n",
    "\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    \n",
    "    Xmin = 0.0\n",
    "    Xmax = 255.0\n",
    "\n",
    "    norm_img = np.empty_like(image_data, dtype=np.float32)\n",
    "\n",
    "    norm_img = a + (image_data - Xmin)*(b-a)/(Xmax - Xmin)\n",
    "\n",
    "    return norm_img\n",
    "\n",
    "train_features = normalize_color(X_train)\n",
    "test_features = normalize_color(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn labels into numbers and apply One-Hot Encoding\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "train_labels = encoder.transform(y_train)\n",
    "test_labels = encoder.transform(y_test)\n",
    "\n",
    "# Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)\n",
    "is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Describe the techniques used to preprocess the data\n",
    "\n",
    "Answer:\n",
    "\n",
    "The images were normalized in all three RGB channels ranging from 0 to 255. We create a batch so it restricts memory limitations so it doesn't work on the entire data set at the same time. This is done during the test and the testing. \n",
    "\n",
    "We normalize so the gradients are manageable. If we have each number ranging from 0 to 255 as it would in full RBG it would require a large amount of numbers in the weight matrices. If we normalize the data set the issue can be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Descirbe how you set up the training, validation and testing data for your model. If you generated additional data, why?\n",
    "\n",
    "Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "train_features = np.array(train['features'])\n",
    "train_labels = np.array(train['labels'])\n",
    "\n",
    "inputs_per_class = np.bincount(train_labels)\n",
    "max_inputs = np.max(inputs_per_class)\n",
    "\n",
    "mpl_fig = plt.figure()\n",
    "ax = mpl_fig.add_subplot(111)\n",
    "ax.set_ylabel('Inputs')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Number of inputs per class')\n",
    "ax.bar(range(len(inputs_per_class)), inputs_per_class, 1/3, color='blue', label='Inputs per class')\n",
    "plt.show()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    for j in range(len(train_labels)):\n",
    "        if (i == train_labels[j]):\n",
    "            print('Class: ', i)\n",
    "            plt.imshow(train_features[j])\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Regenerating images by rotating in between +/-20 degrees. \n",
    "### Credit to Mehdi Sqalli https://github.com/MehdiSv/TrafficSignsRecognition/\n",
    "\n",
    "print('Regenerating data...')\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "# Generate additional data for underrepresented classes\n",
    "print('Generating additional data...')\n",
    "angles = [-5, 5, -10, 10, -15, 15, -20, 20]\n",
    "\n",
    "for i in range(len(inputs_per_class)):\n",
    "    input_ratio = min(int(max_inputs / inputs_per_class[i]) - 1, len(angles) - 1)\n",
    "\n",
    "    if input_ratio <= 1:\n",
    "        continue\n",
    "\n",
    "    new_features = []\n",
    "    new_labels = []\n",
    "    mask = np.where(train_labels == i)\n",
    "\n",
    "    for j in range(input_ratio):\n",
    "        for feature in train_features[mask]:\n",
    "            new_features.append(scipy.ndimage.rotate(feature, angles[j], reshape=False))\n",
    "            new_labels.append(i)\n",
    "\n",
    "    train_features = np.append(train_features, new_features, axis=0)\n",
    "    train_labels = np.append(train_labels, new_labels, axis=0)\n",
    "\n",
    "# Normalize features\n",
    "print('Normalizing features...')\n",
    "train_features = train_features / 255. * 0.8 + 0.1\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "print('Randomizing datasets...')\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "   train_features,\n",
    "   train_labels,\n",
    "   test_size=0.2,\n",
    "   random_state=832289\n",
    ")\n",
    "\n",
    "print('Data preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Creating network architecture...')\n",
    "import tensorflow as tf\n",
    "# Input dimensions\n",
    "image_width = len(train_features[0][0])\n",
    "image_height = len(train_features[0])\n",
    "color_channels = len(train_features[0][0][0])\n",
    "\n",
    "# Convolutional layer patch and output size\n",
    "filter_width = 3\n",
    "filter_height = 3\n",
    "conv_k_output = 128\n",
    "\n",
    "# Dimension parameters for each fully connected layer\n",
    "fc_params = [\n",
    "    image_width * image_height * conv_k_output,\n",
    "    1024,\n",
    "    1024,\n",
    "    n_classes\n",
    "]\n",
    "\n",
    "# Build weights and biases\n",
    "conv2d_weight = None\n",
    "conv2d_bias = None\n",
    "fc_weights = []\n",
    "fc_biases = []\n",
    "\n",
    "with tf.variable_scope('BONHOMME', reuse=False):\n",
    "    conv2d_weight = tf.get_variable(\"conv2w\", shape=[filter_width, filter_height, color_channels, conv_k_output], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    conv2d_bias = tf.get_variable(\"conv2b\", shape=[conv_k_output], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    for i in range(len(fc_params) - 1):\n",
    "        fc_weights.append(tf.get_variable('fc_weight' + str(i), shape=[fc_params[i], fc_params[i + 1]], initializer=tf.contrib.layers.xavier_initializer()))\n",
    "        fc_biases.append(tf.get_variable('fc_bias' + str(i), shape=[fc_params[i + 1]], initializer=tf.contrib.layers.xavier_initializer()))\n",
    "\n",
    "# One-hot encoded training and validation labels\n",
    "oh_train_labels = tf.one_hot(train_labels, n_classes).eval(session=tf.Session())\n",
    "oh_valid_labels = tf.one_hot(valid_labels, n_classes).eval(session=tf.Session())\n",
    "\n",
    "# Input placeholders\n",
    "input_ph = tf.placeholder(tf.float32, shape=[None, image_width, image_height, color_channels])\n",
    "labels_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "# Convolutional layer\n",
    "network = tf.nn.conv2d(input_ph, conv2d_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "network = tf.nn.bias_add(network, conv2d_bias)\n",
    "network = tf.nn.relu(network)\n",
    "\n",
    "# Fully connected layers\n",
    "for i in range(len(fc_weights)):\n",
    "    network = tf.matmul(tf.contrib.layers.flatten(network), fc_weights[i]) + fc_biases[i]\n",
    "    if i < len(fc_weights) - 1: # No relu after last FC layer\n",
    "        network = tf.nn.relu(network)\n",
    "\n",
    "# Loss computation\n",
    "prediction = tf.nn.softmax(network)\n",
    "cross_entropy = -tf.reduce_sum(labels_ph * tf.log(prediction + 1e-6), reduction_indices=1)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Accuracy computation\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels_ph, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Network architecture created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = np.array(test_features) / 255 * 0.8 + 0.1\n",
    "oh_test_labels = tf.one_hot(test_labels, n_classes).eval(session=tf.Session())\n",
    "print('Test label one hot encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def run_batch(session, network, features, labels):\n",
    "    batch_count = int(len(features) / batch_size)\n",
    "    accuracy = 0\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        batch_start = i * batch_size\n",
    "        accuracy += session.run(\n",
    "            network,\n",
    "            feed_dict={\n",
    "                input_ph: features[batch_start:batch_start + batch_size],\n",
    "                labels_ph: labels[batch_start:batch_start + batch_size]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return accuracy / batch_count\n",
    "\n",
    "print('Run batch function created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "training_epochs = 50\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "session = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "session.run(init)\n",
    "batch_count = int(len(train_features) / batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch + 1, training_epochs), unit='batches')\n",
    "\n",
    "    # The training cycle\n",
    "    for batch_i in batches_pbar:\n",
    "        batch_start = batch_i * batch_size\n",
    "        batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "        batch_labels = oh_train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "        _, l = session.run(\n",
    "            [optimizer, loss],\n",
    "            feed_dict={input_ph: batch_features, labels_ph: batch_labels})\n",
    "\n",
    "        if not batch_i % log_batch_step:\n",
    "            training_accuracy = session.run(\n",
    "                accuracy,\n",
    "                feed_dict={input_ph: batch_features, labels_ph: batch_labels}\n",
    "            )\n",
    "\n",
    "            idx = np.random.randint(len(valid_features), size=int(batch_size * .2))\n",
    "\n",
    "            validation_accuracy = session.run(\n",
    "                accuracy,\n",
    "                feed_dict={input_ph: valid_features[idx,:], labels_ph: oh_valid_labels[idx,:]}\n",
    "            )\n",
    "\n",
    "            # Log batches\n",
    "            previous_batch = batches[-1] if batches else 0\n",
    "            batches.append(log_batch_step + previous_batch)\n",
    "            loss_batch.append(l)\n",
    "            train_acc_batch.append(training_accuracy)\n",
    "            valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "\n",
    "validation_accuracy = run_batch(session, accuracy, valid_features, oh_valid_labels)    \n",
    "test_accuracy = run_batch(session, accuracy, test_features, oh_test_labels)\n",
    "\n",
    "print('Final validation accuracy: ', validation_accuracy)\n",
    "print('Final test accuracy: ', test_accuracy)\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'b', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batch_size = 250\n",
    "y_pred_cls = tf.argmax(prediction, dimension=1)\n",
    "test_cls = np.argmax(oh_test_labels, axis=1)\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "img_shape = (32, 32, 3)\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(np.argmax(cls_true[i]))\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(np.argmax(cls_true[i]), np.argmax(cls_pred[i]))\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(cls_pred):\n",
    "    cm = confusion_matrix(y_true=test_cls,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    plt.figure(figsize=(40,40))\n",
    "    rcParams['figure.figsize'] = 13, 13\n",
    "    plt.matshow(cm)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(n_classes)\n",
    "    plt.xticks(tick_marks, range(n_classes))\n",
    "    plt.yticks(tick_marks, range(n_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_example_errors(cls_pred, correct):\n",
    "\n",
    "    incorrect = (correct == False)    \n",
    "    images = test_features[incorrect]    \n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = test_cls[incorrect]    \n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])\n",
    "    \n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    num_test = len(test_features)\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        batch_features = test_features[i:j]\n",
    "        batch_labels = oh_test_labels[i:j]\n",
    "        \n",
    "        feed_dict={input_ph: batch_features, labels_ph: batch_labels}\n",
    "\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    correct = (test_cls == cls_pred)\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n",
    "\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)\n",
    "\n",
    "print_test_accuracy(show_example_errors=False, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test the Model on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.image as mpimg\n",
    "import os, sys\n",
    "\n",
    "imgs = ['50SpeedLimit', 'SnowCaution.png', 'childrenCrossing.png', 'hochwasser.png', 'priority.png']\n",
    "\n",
    "new_input = []\n",
    "\n",
    "for imgname in imgs:\n",
    "    image = mpimg.imread('images/' + imgname)\n",
    "    new_input.append(image)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run the predictions here\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "new_predictions = session.run(prediction, feed_dict={input_ph: new_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed\n",
    "print(new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(session.run(tf.nn.top_k(prediction, 2), feed_dict={input_ph: new_input}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "\n",
    "Describe the techniques used to preprocess the data\n",
    "\n",
    "Answer:\n",
    "The images were normalized in all three RGB channels ranging from 0 to 255. We create a batch so it restricts memory limitations so it doesn't work on the entire data set at the same time. This is done during the test and the testing.\n",
    "We normalize so the gradients are manageable. If we have each number ranging from 0 to 255 as it would in full RBG it would require a large amount of numbers in the weight matrices. If we normalize the data set the issue can be avoided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took 20% of the training data as validation data. Based on some of the test results I got from tweaking the validation data 20% seemed like a good number to not overfit the data. Until I was satisfied with the results I didn't use the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is a Convolutional Neural Network with a patch size of 3x3, a stride of 1, SAME padding and a depth of 64.\n",
    "The second and third layers are fully connected layers with a width of 512.\n",
    "The final layer is a fully connected layer with a width of 43 (the amount of classes)\n",
    "I used the LeNet lab as a model for the architecture while applying the modifications I learned from the lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the AdamOptimizer with a learning rate of 0.001\n",
    "I used a batch size of 250 and 50 training epochs.\n",
    "After numerous tests, the learning rate seemed to learn fairly quickly and it was enough to avoid getting stuck in a local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up using a decent sized network due to the simplicity of the signs. I at first tried a larger network but the results ended up roughly the same but the computation time was drastically higher. I used a low amount of epochs because the results did not vary enough after about 30-40 epochs. The results are satisfying but the computation time was quite long even on my Nvidia GTX 1080."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to choose signs that I felt were very important and very common. The ice warning sign is a very important one because we are currently facing issues with developing safety precautions for driving in heavy snow. I also chose a childrens crossing sign because children could be not paying attention and cross the street at any given moment so being able to identify this sign and have the car drive cautiously is very important."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
